{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2e4ce44",
   "metadata": {},
   "source": [
    "## Phase 4: Transformer-based NLP (BERT)\n",
    "\n",
    "This is the stage where:\n",
    "\n",
    "Accuracy usually improves significantly\n",
    "\n",
    "You work with pretrained language models\n",
    "\n",
    "You connect to LLM concepts asked in interviews\n",
    "\n",
    "You’ll learn:\n",
    "\n",
    "Tokenizers\n",
    "\n",
    "Transformers\n",
    "\n",
    "Pretrained models\n",
    "\n",
    "Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "add3d2d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\great\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (5.1.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=1.3.0 in c:\\users\\great\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\great\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\nishi\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (26.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\great\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\great\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2026.1.15)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\great\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: typer-slim in c:\\users\\great\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.23.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\great\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\great\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (4.67.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\great\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (3.24.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\great\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (2026.2.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in c:\\users\\great\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\great\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (0.28.1)\n",
      "Requirement already satisfied: shellingham in c:\\users\\great\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (1.5.4)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in c:\\users\\great\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\nishi\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: typer>=0.23.1 in c:\\users\\great\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer-slim->transformers) (0.23.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\great\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (4.12.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\great\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\great\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\great\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\great\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (0.16.0)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\great\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer>=0.23.1->typer-slim->transformers) (8.3.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\great\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer>=0.23.1->typer-slim->transformers) (14.3.2)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in c:\\users\\great\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer>=0.23.1->typer-slim->transformers) (0.0.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\great\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich>=10.11.0->typer>=0.23.1->typer-slim->transformers) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\nishi\\appdata\\roaming\\python\\python312\\site-packages (from rich>=10.11.0->typer>=0.23.1->typer-slim->transformers) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\great\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.23.1->typer-slim->transformers) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a5c8724",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script isympy.exe is installed in 'c:\\Users\\great\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts torchfrtrace.exe and torchrun.exe are installed in 'c:\\Users\\great\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.10.0-cp312-cp312-win_amd64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\great\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.24.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\great\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.15.0)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx>=2.5.1 (from torch)\n",
      "  Using cached networkx-3.6.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\great\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2026.2.0)\n",
      "Collecting setuptools (from torch)\n",
      "  Downloading setuptools-82.0.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Using cached markupsafe-3.0.3-cp312-cp312-win_amd64.whl.metadata (2.8 kB)\n",
      "Downloading torch-2.10.0-cp312-cp312-win_amd64.whl (113.8 MB)\n",
      "   ---------------------------------------- 0.0/113.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/113.8 MB 5.6 MB/s eta 0:00:21\n",
      "    --------------------------------------- 2.4/113.8 MB 6.1 MB/s eta 0:00:19\n",
      "   - -------------------------------------- 3.7/113.8 MB 6.2 MB/s eta 0:00:18\n",
      "   - -------------------------------------- 4.7/113.8 MB 6.2 MB/s eta 0:00:18\n",
      "   - -------------------------------------- 5.2/113.8 MB 5.5 MB/s eta 0:00:20\n",
      "   - -------------------------------------- 5.5/113.8 MB 5.4 MB/s eta 0:00:21\n",
      "   - -------------------------------------- 5.5/113.8 MB 5.4 MB/s eta 0:00:21\n",
      "   - -------------------------------------- 5.5/113.8 MB 5.4 MB/s eta 0:00:21\n",
      "   - -------------------------------------- 5.5/113.8 MB 5.4 MB/s eta 0:00:21\n",
      "   - -------------------------------------- 5.5/113.8 MB 5.4 MB/s eta 0:00:21\n",
      "   -- ------------------------------------- 5.8/113.8 MB 2.6 MB/s eta 0:00:42\n",
      "   -- ------------------------------------- 5.8/113.8 MB 2.6 MB/s eta 0:00:42\n",
      "   -- ------------------------------------- 5.8/113.8 MB 2.6 MB/s eta 0:00:42\n",
      "   -- ------------------------------------- 5.8/113.8 MB 2.6 MB/s eta 0:00:42\n",
      "   -- ------------------------------------- 5.8/113.8 MB 2.6 MB/s eta 0:00:42\n",
      "   -- ------------------------------------- 5.8/113.8 MB 2.6 MB/s eta 0:00:42\n",
      "   -- ------------------------------------- 5.8/113.8 MB 2.6 MB/s eta 0:00:42\n",
      "   -- ------------------------------------- 6.3/113.8 MB 1.7 MB/s eta 0:01:05\n",
      "   -- ------------------------------------- 6.3/113.8 MB 1.7 MB/s eta 0:01:05\n",
      "   -- ------------------------------------- 6.6/113.8 MB 1.6 MB/s eta 0:01:07\n",
      "   -- ------------------------------------- 6.8/113.8 MB 1.6 MB/s eta 0:01:09\n",
      "   -- ------------------------------------- 6.8/113.8 MB 1.6 MB/s eta 0:01:09\n",
      "   -- ------------------------------------- 7.1/113.8 MB 1.5 MB/s eta 0:01:12\n",
      "   -- ------------------------------------- 7.1/113.8 MB 1.5 MB/s eta 0:01:12\n",
      "   -- ------------------------------------- 7.1/113.8 MB 1.5 MB/s eta 0:01:12\n",
      "   -- ------------------------------------- 7.3/113.8 MB 1.4 MB/s eta 0:01:17\n",
      "   -- ------------------------------------- 7.9/113.8 MB 1.4 MB/s eta 0:01:17\n",
      "   -- ------------------------------------- 8.1/113.8 MB 1.4 MB/s eta 0:01:16\n",
      "   --- ------------------------------------ 8.7/113.8 MB 1.4 MB/s eta 0:01:14\n",
      "   --- ------------------------------------ 9.4/113.8 MB 1.5 MB/s eta 0:01:09\n",
      "   --- ------------------------------------ 10.0/113.8 MB 1.6 MB/s eta 0:01:07\n",
      "   --- ------------------------------------ 10.5/113.8 MB 1.6 MB/s eta 0:01:06\n",
      "   --- ------------------------------------ 11.0/113.8 MB 1.6 MB/s eta 0:01:04\n",
      "   ---- ----------------------------------- 11.5/113.8 MB 1.7 MB/s eta 0:01:02\n",
      "   ---- ----------------------------------- 12.1/113.8 MB 1.7 MB/s eta 0:01:02\n",
      "   ---- ----------------------------------- 12.6/113.8 MB 1.7 MB/s eta 0:01:00\n",
      "   ---- ----------------------------------- 13.4/113.8 MB 1.7 MB/s eta 0:00:58\n",
      "   ---- ----------------------------------- 13.9/113.8 MB 1.8 MB/s eta 0:00:57\n",
      "   ----- ---------------------------------- 14.7/113.8 MB 1.8 MB/s eta 0:00:55\n",
      "   ----- ---------------------------------- 15.5/113.8 MB 1.9 MB/s eta 0:00:53\n",
      "   ----- ---------------------------------- 16.3/113.8 MB 1.9 MB/s eta 0:00:51\n",
      "   ----- ---------------------------------- 16.8/113.8 MB 1.9 MB/s eta 0:00:50\n",
      "   ------ --------------------------------- 17.6/113.8 MB 2.0 MB/s eta 0:00:49\n",
      "   ------ --------------------------------- 17.8/113.8 MB 2.0 MB/s eta 0:00:49\n",
      "   ------ --------------------------------- 18.4/113.8 MB 2.0 MB/s eta 0:00:49\n",
      "   ------ --------------------------------- 19.1/113.8 MB 2.0 MB/s eta 0:00:47\n",
      "   ------ --------------------------------- 19.7/113.8 MB 2.0 MB/s eta 0:00:47\n",
      "   ------- -------------------------------- 20.4/113.8 MB 2.1 MB/s eta 0:00:45\n",
      "   ------- -------------------------------- 21.2/113.8 MB 2.1 MB/s eta 0:00:44\n",
      "   ------- -------------------------------- 22.0/113.8 MB 2.1 MB/s eta 0:00:43\n",
      "   ------- -------------------------------- 22.5/113.8 MB 2.2 MB/s eta 0:00:43\n",
      "   -------- ------------------------------- 23.1/113.8 MB 2.2 MB/s eta 0:00:42\n",
      "   -------- ------------------------------- 23.9/113.8 MB 2.2 MB/s eta 0:00:42\n",
      "   -------- ------------------------------- 24.6/113.8 MB 2.2 MB/s eta 0:00:41\n",
      "   -------- ------------------------------- 25.2/113.8 MB 2.2 MB/s eta 0:00:40\n",
      "   --------- ------------------------------ 26.0/113.8 MB 2.3 MB/s eta 0:00:39\n",
      "   --------- ------------------------------ 26.7/113.8 MB 2.3 MB/s eta 0:00:39\n",
      "   --------- ------------------------------ 27.5/113.8 MB 2.3 MB/s eta 0:00:38\n",
      "   --------- ------------------------------ 28.3/113.8 MB 2.3 MB/s eta 0:00:37\n",
      "   ---------- ----------------------------- 28.8/113.8 MB 2.3 MB/s eta 0:00:37\n",
      "   ---------- ----------------------------- 29.6/113.8 MB 2.4 MB/s eta 0:00:36\n",
      "   ---------- ----------------------------- 30.1/113.8 MB 2.4 MB/s eta 0:00:36\n",
      "   ---------- ----------------------------- 30.7/113.8 MB 2.4 MB/s eta 0:00:35\n",
      "   ---------- ----------------------------- 31.2/113.8 MB 2.4 MB/s eta 0:00:35\n",
      "   ----------- ---------------------------- 31.7/113.8 MB 2.4 MB/s eta 0:00:35\n",
      "   ----------- ---------------------------- 32.2/113.8 MB 2.4 MB/s eta 0:00:35\n",
      "   ----------- ---------------------------- 33.0/113.8 MB 2.4 MB/s eta 0:00:34\n",
      "   ----------- ---------------------------- 33.6/113.8 MB 2.4 MB/s eta 0:00:34\n",
      "   ------------ --------------------------- 34.3/113.8 MB 2.4 MB/s eta 0:00:33\n",
      "   ------------ --------------------------- 35.1/113.8 MB 2.4 MB/s eta 0:00:33\n",
      "   ------------ --------------------------- 35.7/113.8 MB 2.4 MB/s eta 0:00:32\n",
      "   ------------ --------------------------- 36.2/113.8 MB 2.4 MB/s eta 0:00:32\n",
      "   ------------ --------------------------- 36.7/113.8 MB 2.5 MB/s eta 0:00:32\n",
      "   ------------- -------------------------- 37.5/113.8 MB 2.5 MB/s eta 0:00:31\n",
      "   ------------- -------------------------- 38.3/113.8 MB 2.5 MB/s eta 0:00:31\n",
      "   ------------- -------------------------- 39.1/113.8 MB 2.5 MB/s eta 0:00:30\n",
      "   ------------- -------------------------- 39.6/113.8 MB 2.5 MB/s eta 0:00:30\n",
      "   -------------- ------------------------- 40.4/113.8 MB 2.5 MB/s eta 0:00:29\n",
      "   -------------- ------------------------- 41.2/113.8 MB 2.5 MB/s eta 0:00:29\n",
      "   -------------- ------------------------- 41.9/113.8 MB 2.6 MB/s eta 0:00:29\n",
      "   --------------- ------------------------ 42.7/113.8 MB 2.6 MB/s eta 0:00:28\n",
      "   --------------- ------------------------ 43.3/113.8 MB 2.6 MB/s eta 0:00:28\n",
      "   --------------- ------------------------ 44.0/113.8 MB 2.6 MB/s eta 0:00:27\n",
      "   --------------- ------------------------ 44.3/113.8 MB 2.6 MB/s eta 0:00:27\n",
      "   --------------- ------------------------ 44.6/113.8 MB 2.6 MB/s eta 0:00:27\n",
      "   --------------- ------------------------ 45.1/113.8 MB 2.6 MB/s eta 0:00:27\n",
      "   ---------------- ----------------------- 45.6/113.8 MB 2.6 MB/s eta 0:00:27\n",
      "   ---------------- ----------------------- 46.4/113.8 MB 2.6 MB/s eta 0:00:27\n",
      "   ---------------- ----------------------- 46.9/113.8 MB 2.6 MB/s eta 0:00:26\n",
      "   ---------------- ----------------------- 47.7/113.8 MB 2.6 MB/s eta 0:00:26\n",
      "   ---------------- ----------------------- 48.2/113.8 MB 2.6 MB/s eta 0:00:26\n",
      "   ----------------- ---------------------- 49.0/113.8 MB 2.6 MB/s eta 0:00:25\n",
      "   ----------------- ---------------------- 49.5/113.8 MB 2.6 MB/s eta 0:00:25\n",
      "   ----------------- ---------------------- 50.3/113.8 MB 2.6 MB/s eta 0:00:25\n",
      "   ----------------- ---------------------- 51.1/113.8 MB 2.6 MB/s eta 0:00:24\n",
      "   ------------------ --------------------- 51.9/113.8 MB 2.6 MB/s eta 0:00:24\n",
      "   ------------------ --------------------- 52.4/113.8 MB 2.7 MB/s eta 0:00:24\n",
      "   ------------------ --------------------- 53.2/113.8 MB 2.7 MB/s eta 0:00:23\n",
      "   ------------------ --------------------- 54.0/113.8 MB 2.7 MB/s eta 0:00:23\n",
      "   ------------------- -------------------- 54.5/113.8 MB 2.7 MB/s eta 0:00:23\n",
      "   ------------------- -------------------- 55.1/113.8 MB 2.7 MB/s eta 0:00:23\n",
      "   ------------------- -------------------- 55.8/113.8 MB 2.7 MB/s eta 0:00:22\n",
      "   ------------------- -------------------- 56.1/113.8 MB 2.7 MB/s eta 0:00:22\n",
      "   ------------------- -------------------- 56.4/113.8 MB 2.6 MB/s eta 0:00:22\n",
      "   -------------------- ------------------- 56.9/113.8 MB 2.6 MB/s eta 0:00:22\n",
      "   -------------------- ------------------- 57.7/113.8 MB 2.7 MB/s eta 0:00:22\n",
      "   -------------------- ------------------- 58.5/113.8 MB 2.7 MB/s eta 0:00:21\n",
      "   -------------------- ------------------- 59.2/113.8 MB 2.7 MB/s eta 0:00:21\n",
      "   --------------------- ------------------ 60.3/113.8 MB 2.7 MB/s eta 0:00:20\n",
      "   --------------------- ------------------ 60.8/113.8 MB 2.7 MB/s eta 0:00:20\n",
      "   --------------------- ------------------ 61.6/113.8 MB 2.7 MB/s eta 0:00:20\n",
      "   ---------------------- ----------------- 62.7/113.8 MB 2.7 MB/s eta 0:00:19\n",
      "   ---------------------- ----------------- 63.4/113.8 MB 2.7 MB/s eta 0:00:19\n",
      "   ---------------------- ----------------- 64.5/113.8 MB 2.8 MB/s eta 0:00:18\n",
      "   ---------------------- ----------------- 65.3/113.8 MB 2.8 MB/s eta 0:00:18\n",
      "   ----------------------- ---------------- 66.3/113.8 MB 2.8 MB/s eta 0:00:18\n",
      "   ----------------------- ---------------- 67.4/113.8 MB 2.8 MB/s eta 0:00:17\n",
      "   ----------------------- ---------------- 68.2/113.8 MB 2.8 MB/s eta 0:00:17\n",
      "   ------------------------ --------------- 69.2/113.8 MB 2.8 MB/s eta 0:00:16\n",
      "   ------------------------ --------------- 70.0/113.8 MB 2.9 MB/s eta 0:00:16\n",
      "   ------------------------ --------------- 71.0/113.8 MB 2.9 MB/s eta 0:00:15\n",
      "   ------------------------- -------------- 71.6/113.8 MB 2.9 MB/s eta 0:00:15\n",
      "   ------------------------- -------------- 71.8/113.8 MB 2.8 MB/s eta 0:00:15\n",
      "   ------------------------- -------------- 72.1/113.8 MB 2.8 MB/s eta 0:00:15\n",
      "   ------------------------- -------------- 73.1/113.8 MB 2.9 MB/s eta 0:00:15\n",
      "   ------------------------- -------------- 73.9/113.8 MB 2.9 MB/s eta 0:00:14\n",
      "   -------------------------- ------------- 74.7/113.8 MB 2.9 MB/s eta 0:00:14\n",
      "   -------------------------- ------------- 75.8/113.8 MB 2.9 MB/s eta 0:00:14\n",
      "   -------------------------- ------------- 76.5/113.8 MB 2.9 MB/s eta 0:00:13\n",
      "   --------------------------- ------------ 77.1/113.8 MB 2.9 MB/s eta 0:00:13\n",
      "   --------------------------- ------------ 77.9/113.8 MB 2.9 MB/s eta 0:00:13\n",
      "   --------------------------- ------------ 78.9/113.8 MB 2.9 MB/s eta 0:00:12\n",
      "   ---------------------------- ----------- 80.0/113.8 MB 2.9 MB/s eta 0:00:12\n",
      "   ---------------------------- ----------- 80.7/113.8 MB 2.9 MB/s eta 0:00:12\n",
      "   ---------------------------- ----------- 81.8/113.8 MB 3.0 MB/s eta 0:00:11\n",
      "   ----------------------------- ---------- 82.6/113.8 MB 3.0 MB/s eta 0:00:11\n",
      "   ----------------------------- ---------- 83.6/113.8 MB 3.0 MB/s eta 0:00:11\n",
      "   ----------------------------- ---------- 84.1/113.8 MB 3.0 MB/s eta 0:00:10\n",
      "   ----------------------------- ---------- 84.9/113.8 MB 3.0 MB/s eta 0:00:10\n",
      "   ------------------------------ --------- 85.7/113.8 MB 3.0 MB/s eta 0:00:10\n",
      "   ------------------------------ --------- 86.2/113.8 MB 3.0 MB/s eta 0:00:10\n",
      "   ------------------------------ --------- 86.5/113.8 MB 3.0 MB/s eta 0:00:10\n",
      "   ------------------------------ --------- 86.8/113.8 MB 3.0 MB/s eta 0:00:10\n",
      "   ------------------------------ --------- 87.6/113.8 MB 3.0 MB/s eta 0:00:09\n",
      "   ------------------------------- -------- 88.6/113.8 MB 3.0 MB/s eta 0:00:09\n",
      "   ------------------------------- -------- 89.4/113.8 MB 3.0 MB/s eta 0:00:09\n",
      "   ------------------------------- -------- 90.4/113.8 MB 3.0 MB/s eta 0:00:08\n",
      "   -------------------------------- ------- 91.2/113.8 MB 3.0 MB/s eta 0:00:08\n",
      "   -------------------------------- ------- 92.0/113.8 MB 3.0 MB/s eta 0:00:08\n",
      "   -------------------------------- ------- 92.5/113.8 MB 2.9 MB/s eta 0:00:08\n",
      "   -------------------------------- ------- 93.3/113.8 MB 2.9 MB/s eta 0:00:07\n",
      "   --------------------------------- ------ 94.4/113.8 MB 3.1 MB/s eta 0:00:07\n",
      "   --------------------------------- ------ 95.2/113.8 MB 3.1 MB/s eta 0:00:07\n",
      "   --------------------------------- ------ 95.9/113.8 MB 3.1 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 96.7/113.8 MB 3.1 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 97.8/113.8 MB 3.1 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 98.6/113.8 MB 3.1 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 99.4/113.8 MB 3.2 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 100.1/113.8 MB 3.2 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 100.7/113.8 MB 3.2 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 100.9/113.8 MB 3.2 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 101.4/113.8 MB 3.2 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 101.7/113.8 MB 3.2 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 102.8/113.8 MB 3.2 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 103.3/113.8 MB 3.3 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 104.1/113.8 MB 3.3 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 104.9/113.8 MB 3.3 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 105.6/113.8 MB 3.3 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 105.9/113.8 MB 3.3 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 106.2/113.8 MB 3.4 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 106.7/113.8 MB 3.3 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 107.5/113.8 MB 3.3 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 108.3/113.8 MB 3.4 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 109.3/113.8 MB 3.4 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 109.8/113.8 MB 3.4 MB/s eta 0:00:02\n",
      "   ---------------------------------------  111.1/113.8 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  112.2/113.8 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  113.5/113.8 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  113.5/113.8 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 113.8/113.8 MB 3.4 MB/s eta 0:00:00\n",
      "Using cached networkx-3.6.1-py3-none-any.whl (2.1 MB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading setuptools-82.0.0-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/1.0 MB 5.3 MB/s eta 0:00:00\n",
      "Using cached markupsafe-3.0.3-cp312-cp312-win_amd64.whl (15 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, sympy, setuptools, networkx, MarkupSafe, jinja2, torch\n",
      "Successfully installed MarkupSafe-3.0.3 jinja2-3.1.6 mpmath-1.3.0 networkx-3.6.1 setuptools-82.0.0 sympy-1.14.0 torch-2.10.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "2.10.0+cpu\n"
     ]
    }
   ],
   "source": [
    "%pip install torch\n",
    "import torch\n",
    "print(torch.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f8e283",
   "metadata": {},
   "source": [
    "## Phase 4 Goal\n",
    "\n",
    "In this phase, instead of building models from scratch, we:\n",
    "\n",
    "Text → BERT tokenizer → BERT model → sentiment prediction\n",
    "\n",
    "\n",
    "BERT already:\n",
    "\n",
    "Understands language\n",
    "\n",
    "Knows context\n",
    "\n",
    "Has been trained on massive datasets\n",
    "\n",
    "We just fine-tune it on your sentiment data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b53ea39a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\great\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.0.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\great\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\nishi\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata in c:\\users\\great\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2025.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nishi\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.8.0-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.24.1 in c:\\users\\great\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (2.2.6)\n",
      "Collecting scipy>=1.10.0 (from scikit-learn)\n",
      "  Using cached scipy-1.17.0-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.3.0 (from scikit-learn)\n",
      "  Using cached joblib-1.5.3-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting threadpoolctl>=3.2.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Using cached scikit_learn-1.8.0-cp312-cp312-win_amd64.whl (8.0 MB)\n",
      "Using cached joblib-1.5.3-py3-none-any.whl (309 kB)\n",
      "Using cached scipy-1.17.0-cp312-cp312-win_amd64.whl (36.3 MB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.5.3 scikit-learn-1.8.0 scipy-1.17.0 threadpoolctl-3.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas\n",
    "import pandas as pd\n",
    "\n",
    "%pip install scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from transformers import (\n",
    "    BertTokenizer,\n",
    "    BertForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dde14f4",
   "metadata": {},
   "source": [
    "## Step 3: Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc9045d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/sentimentdataset.csv\")\n",
    "\n",
    "texts = df[\"Text\"].astype(str)\n",
    "labels = df[\"Sentiment\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0396a795",
   "metadata": {},
   "source": [
    "## Step 4: Encode labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c1e274c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a541740",
   "metadata": {},
   "source": [
    "## Step 5: Train–test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "161ea142",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    texts, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d2570f",
   "metadata": {},
   "source": [
    "## Step 6: Load BERT tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7807420",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751bbeab",
   "metadata": {},
   "source": [
    "## Step 7: Tokenize text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c35a64f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(\n",
    "    list(X_train),\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    max_length=64\n",
    ")\n",
    "\n",
    "test_encodings = tokenizer(\n",
    "    list(X_test),\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    max_length=64\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24ff501",
   "metadata": {},
   "source": [
    "## Step 8: Create PyTorch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f21bdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "753feb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SentimentDataset(train_encodings, list(y_train))\n",
    "test_dataset = SentimentDataset(test_encodings, list(y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed7fdac",
   "metadata": {},
   "source": [
    "## Step 9: Load BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e818776c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "\nBertForSequenceClassification requires the PyTorch library but it was not found in your environment. Check out the instructions on the\ninstallation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.\nPlease note that you may need to restart your runtime after installation.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model = \u001b[43mBertForSequenceClassification\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m(\n\u001b[32m      2\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mbert-base-uncased\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      3\u001b[39m     num_labels=\u001b[38;5;28mlen\u001b[39m(encoder.classes_)\n\u001b[32m      4\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\great\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1893\u001b[39m, in \u001b[36mDummyObject.__getattribute__\u001b[39m\u001b[34m(cls, key)\u001b[39m\n\u001b[32m   1891\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (key.startswith(\u001b[33m\"\u001b[39m\u001b[33m_\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key != \u001b[33m\"\u001b[39m\u001b[33m_from_config\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m key == \u001b[33m\"\u001b[39m\u001b[33mis_dummy\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m key == \u001b[33m\"\u001b[39m\u001b[33mmro\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m key == \u001b[33m\"\u001b[39m\u001b[33mcall\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1892\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__getattribute__\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m1893\u001b[39m \u001b[43mrequires_backends\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_backends\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\great\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1879\u001b[39m, in \u001b[36mrequires_backends\u001b[39m\u001b[34m(obj, backends)\u001b[39m\n\u001b[32m   1876\u001b[39m         failed.append(msg.format(name))\n\u001b[32m   1878\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m failed:\n\u001b[32m-> \u001b[39m\u001b[32m1879\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m.join(failed))\n",
      "\u001b[31mImportError\u001b[39m: \nBertForSequenceClassification requires the PyTorch library but it was not found in your environment. Check out the instructions on the\ninstallation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.\nPlease note that you may need to restart your runtime after installation.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    num_labels=len(encoder.classes_)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8618073f",
   "metadata": {},
   "source": [
    "## Step 10: Training configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6399ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`logging_dir` is deprecated and will be removed in v5.2. Please set `TENSORBOARD_LOGGING_DIR` instead.\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8071d108",
   "metadata": {},
   "source": [
    "## Step 11: Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f810f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m trainer = Trainer(\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     model=model,\n\u001b[32m      3\u001b[39m     args=training_args,\n\u001b[32m      4\u001b[39m     train_dataset=train_dataset,\n\u001b[32m      5\u001b[39m     eval_dataset=test_dataset\n\u001b[32m      6\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b16d5f7",
   "metadata": {},
   "source": [
    "## Step 12: Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc9717c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m trainer.train()\n",
      "\u001b[31mNameError\u001b[39m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
